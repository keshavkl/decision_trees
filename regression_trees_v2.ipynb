{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures, KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'dubai_cars_dataset.csv'\n",
    "cars_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows and data info\n",
    "print(cars_data.head())\n",
    "print(cars_data.info())\n",
    "\n",
    "# Drop less relevant columns\n",
    "cars_data.drop(['address', 'country', 'city', 'area_name', 'location_name'], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with median for numerical columns and mode for categorical\n",
    "for column in cars_data.columns:\n",
    "    if cars_data[column].dtype == 'object':\n",
    "        # Using mode for categorical data\n",
    "        mode_value = cars_data[column].mode()[0]\n",
    "        cars_data[column] = cars_data[column].fillna(mode_value)\n",
    "    else:\n",
    "        # Using median for numerical data\n",
    "        median_value = cars_data[column].median()\n",
    "        cars_data[column] = cars_data[column].fillna(median_value)\n",
    "\n",
    "def convert_hp_range(hp_string):\n",
    "    if '-' in hp_string:\n",
    "        low, high = hp_string.split('-')\n",
    "        low = int(low.strip().split(' ')[0])\n",
    "        high = int(high.strip().split(' ')[0])\n",
    "        return (low + high) / 2\n",
    "    else:\n",
    "        # Remove any characters that are not digits or decimals and check if empty\n",
    "        hp_clean = ''.join(filter(str.isdigit, hp_string.split(' ')[0]))\n",
    "        return float(hp_clean) if hp_clean else np.nan\n",
    "\n",
    "# Clean 'horsepower'\n",
    "cars_data['horsepower'] = cars_data['horsepower'].apply(convert_hp_range)\n",
    "\n",
    "# Assuming 'engine_capacity_cc' might also have similar issues, apply a generic cleaning\n",
    "def clean_numeric(column_value):\n",
    "    # Remove non-numeric characters and check if empty\n",
    "    cleaned_value = ''.join(filter(str.isdigit, str(column_value).split(' ')[0]))\n",
    "    return float(cleaned_value) if cleaned_value else np.nan\n",
    "\n",
    "# Clean 'engine_capacity_cc'\n",
    "cars_data['engine_capacity_cc'] = cars_data['engine_capacity_cc'].apply(clean_numeric)\n",
    "\n",
    "# If there are NaNs introduced by cleaning, you can fill them with the median of the column\n",
    "cars_data['horsepower'] = cars_data['horsepower'].fillna(cars_data['horsepower'].median())\n",
    "cars_data['engine_capacity_cc'] = cars_data['engine_capacity_cc'].fillna(cars_data['engine_capacity_cc'].median())\n",
    "\n",
    "# Verify the changes and proceed\n",
    "print(cars_data[['horsepower', 'engine_capacity_cc']].head())\n",
    "\n",
    "# Polynomial features for horsepower and engine capacity\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "important_features = cars_data[['horsepower', 'engine_capacity_cc']]  # assuming conversion to numeric already done\n",
    "poly_features = poly.fit_transform(important_features)\n",
    "poly_features_df = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(['horsepower', 'engine_capacity_cc']))\n",
    "\n",
    "# Add polynomial features to the dataframe\n",
    "cars_data = pd.concat([cars_data, poly_features_df], axis=1)\n",
    "\n",
    "# Binning 'year' and 'kilometers'\n",
    "binning = KBinsDiscretizer(n_bins=5, encode='onehot-dense', strategy='quantile')\n",
    "binned_columns = cars_data[['year', 'kilometers']]\n",
    "binned_features = binning.fit_transform(binned_columns)\n",
    "binned_features_df = pd.DataFrame(binned_features, columns=['year_bin' + str(i) for i in range(5)] + ['kilometers_bin' + str(i) for i in range(5)])\n",
    "\n",
    "# Add binned features to the dataframe\n",
    "cars_data = pd.concat([cars_data, binned_features_df], axis=1)\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Select categorical data\n",
    "categorical_data = cars_data.select_dtypes(include=['object'])\n",
    "\n",
    "# Fit and transform categorical data\n",
    "encoded_columns = encoder.fit_transform(categorical_data).toarray()\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(categorical_data.columns))\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded columns\n",
    "cars_data.drop(columns=categorical_data.columns, inplace=True)\n",
    "cars_data = pd.concat([cars_data, encoded_df], axis=1)\n",
    "\n",
    "# Now, let's prepare the dataset again for training\n",
    "X = cars_data.drop('price', axis=1)\n",
    "y = cars_data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Regressor\n",
    "#regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Re-fit the model with new features\n",
    "\n",
    "#regressor.fit(X_train, y_train)\n",
    "#y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model again\n",
    "#mse = mean_squared_error(y_test, y_pred)\n",
    "#r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#print(f'Mean Squared Error: {mse:.2f}')\n",
    "#print(f'R² Score: {r2:.2f}')\n",
    "\n",
    "# Adding cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize the Decision Tree Regressor\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Assuming the dataset is ready and X, y are defined\n",
    "# If X and y are not defined, you need to split your dataset appropriately\n",
    "# X = cars_data.drop('price', axis=1)\n",
    "# y = cars_data['price']\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "scores = cross_val_score(regressor, X, y, cv=10, scoring='r2')\n",
    "\n",
    "# Calculate the average R² score across all folds\n",
    "average_r2 = np.mean(scores)\n",
    "\n",
    "# Display the results\n",
    "print(\"R² scores for each fold:\", scores)\n",
    "print(\"Average R² score:\", average_r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
