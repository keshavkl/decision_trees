{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'power_co_churn.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "// write a code to read multiple excel files and merge them into one dataframe\n",
    "# Get a list of all Excel files in the directory\n",
    "excel_files = glob.glob('*.xlsx')\n",
    "\n",
    "# Initialize an empty list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Read each Excel file and append its dataframe to the list\n",
    "for file in excel_files:\n",
    "    df = pd.read_excel(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Merge all dataframes into one\n",
    "merged_df = pd.concat(dfs)\n",
    "\n",
    "# Print the merged dataframe\n",
    "print(merged_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id: Unique identifier for the customer.\n",
    "channel_sales: The sales channel through which the customer was acquired.\n",
    "cons_12m: Electricity consumption of the past 12 months.\n",
    "cons_gas_12m: Gas consumption of the past 12 months.\n",
    "cons_last_month: Electricity consumption in the last month.\n",
    "date_activ: The date the contract was activated.\n",
    "date_end: The date the contract ends.\n",
    "date_modif_prod: The last date the product was modified.\n",
    "date_renewal: The last date the contract was renewed.\n",
    "forecast_cons_12m: Forecasted electricity consumption for the next 12 months.\n",
    "has_gas: Whether the customer has gas (t/f).\n",
    "imp_cons: Imputed consumption.\n",
    "margin_gross_pow_ele: Gross margin on power subscription.\n",
    "margin_net_pow_ele: Net margin on power subscription.\n",
    "nb_prod_act: Number of active products.\n",
    "net_margin: Net margin.\n",
    "num_years_antig: Number of years the customer has been active.\n",
    "origin_up: Origin of the customer.\n",
    "pow_max: Maximum power consumption.\n",
    "churn: Whether the customer churned (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'MISSING' with NaN for easier handling\n",
    "data.replace(\"MISSING\", pd.NA, inplace=True)\n",
    "\n",
    "# Convert date columns to datetime, handling errors by coercing them to NaT (not a time)\n",
    "date_cols = ['date_activ', 'date_end', 'date_modif_prod', 'date_renewal']\n",
    "for col in date_cols:\n",
    "    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "\n",
    "# Check for missing values and unique values in categorical columns to identify gibberish\n",
    "print(data.isnull().sum())\n",
    "print(data['channel_sales'].unique())  # Check for gibberish values\n",
    "\n",
    "# Update: Let's handle the rows with any gibberish data, for instance in `origin_up`\n",
    "print(data['origin_up'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Handling missing values: Imputing with a placeholder value for categorical columns\n",
    "data['channel_sales'].fillna('unknown', inplace=True)\n",
    "data['origin_up'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "categorical_cols = ['channel_sales', 'origin_up', 'has_gas']\n",
    "encoded_data = encoder.fit_transform(data[categorical_cols]).toarray()  # Convert to dense format using toarray()\n",
    "\n",
    "# Create a DataFrame from the encoded data with appropriate column names\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Drop the original categorical columns and concatenate the encoded columns\n",
    "data = data.drop(columns=categorical_cols)\n",
    "data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X = data.drop('churn', axis=1)\n",
    "y = data['churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the transformed DataFrame ready for modeling\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example transformation: calculating the number of days from a reference date\n",
    "reference_date = pd.Timestamp('today')\n",
    "for col in date_cols:\n",
    "    X_train[col + '_days'] = (reference_date - X_train[col]).dt.days\n",
    "    X_test[col + '_days'] = (reference_date - X_test[col]).dt.days\n",
    "\n",
    "# Drop the original datetime columns from the datasets\n",
    "X_train.drop(columns=date_cols, inplace=True)\n",
    "X_test.drop(columns=date_cols, inplace=True)\n",
    "\n",
    "print(\"Columns in X_train:\", X_train.columns)\n",
    "print(\"Columns in X_test:\", X_test.columns)\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Drop the ID column\n",
    "#X_train = X_train.drop(columns=['id'])\n",
    "#X_test = X_test.drop(columns=['id'])\n",
    "\n",
    "# Decision Tree with Gini impurity\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "clf_gini.fit(X_train, y_train)\n",
    "y_pred_gini = clf_gini.predict(X_test)\n",
    "accuracy_gini = accuracy_score(y_test, y_pred_gini)\n",
    "print(f'Accuracy with Gini impurity: {accuracy_gini:.2f}')\n",
    "print(classification_report(y_test, y_pred_gini))\n",
    "\n",
    "# Decision Tree with Entropy\n",
    "clf_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "y_pred_entropy = clf_entropy.predict(X_test)\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred_entropy)\n",
    "print(f'Accuracy with Entropy: {accuracy_entropy:.2f}')\n",
    "print(classification_report(y_test, y_pred_entropy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CV to get the best threshold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Set up the Decision Tree Classifier with entropy\n",
    "tree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'min_samples_split': range(2, 50)  # Testing splits from 2 up to 50\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=tree, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Optionally, evaluate it on the test set\n",
    "best_tree = grid_search.best_estimator_\n",
    "y_pred = best_tree.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy: {:.2f}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Predict probabilities\n",
    "y_scores = best_tree.predict_proba(X_test)[:, 1]  # score = probability of positive class\n",
    "\n",
    "# Generate ROC curve data\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "\n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f\"The AUC is: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
